\section{Exploring Thread Interleaving Space}
\label{s:design}

In this section, we describe our approach to effectively achieve
\textbf{Design goal 1} and \textbf{2}.
%
We first explain the key idea of our approach~(\autoref{ss:overview}). 
At first, we illustrate our concurrency
coverage metric to express combinatorial interleavings 
(\textbf{Design goal 1})~(\autoref{ss:coverage}) and the instruction scheduling mechanism
to quickly saturate the coverage metric (\textbf{Design goal 2})~(\autoref{ss:scheduler}).
%While this section focuses only on how to explore the search space of
%thread interleaving with a given multi-thread input, the whole design
%of \sys will be explained later in \autoref{s:impl}.


\subsection{Key Idea: Segmentizing thread interleaving}
\label{ss:overview}

\begin{table}[t]
  \centering
  \input{table/learningfrommistakes.tex}
  \caption{Statistics provided by Shan Lu
    \etal~\cite{learningfrommistakes}, stating the number of
    concurrency bugs according to the number of memory accesses
    involved in the manifestation of a concurrency bug.}
  \label{table:learningfrommistakes}
\end{table}

When fuzzing concurrency bugs with a coverage metric, the fundamental challenge is its large search space because
the combinations of thread interleavings increase the 
the search space exponentially. Therefore, this work seek to 
strike the balance
in the trade-off between bug-finding capability and search 
complexity. Observed by a previous study~\cite{learningfrommistakes}
as shown in \autoref{table:learningfrommistakes}\yj{Do we need the table?}, 92.4\% (97 out of
105) of concurrency bugs manifest when a bug-finding system 
monitors instruction execution orders including \textit{at most} 
four memory accesses referring to the same object\yj{the same address?}.
All other memory
accesses beyond four accesses and their execution orders do not
meaningfully affect manifestation of a concurrency bug. 
The observation also is applied to the example of \autoref{fig:cve-2017-17712}. The uninitialized access bug is triggered by 
the execution order of three
memory accesses (\eg, \texttt{A2}, \texttt{A4} and \texttt{B1}), while
others (\eg, \texttt{A6} and \texttt{B2}) are irrelevant to manifest the
concurrency bug.
Following the observation, this work confines the search space 
to interleaving orders including at most four memory accesses,
which makes the problem of defining a coverage metric tractable while maintaining a strong bug-finding capability.

\PP{Segmentizing thread interleaving}
\yj{rewrite this paragraph. revision point: \\
- If possible, try to put the benefit paragraph before explain how 
to build a segment  \\ 
- how to group the segment. Any constraints to follow?   \\
- The example does not kindly explain how to build a segment.   \\
}
%
Based on the survey, the key idea of our approach is to consider a
thread interleaving as \textit{a composition of interleaving
  segments}, where each interleaving segment represents interleaving
orders between a small number of memory accesses.
%
In particular, once executing threads concurrently, we firstly model
the thread interleaving as a totally-ordered instruction sequence.
%
And then, we group a small number of instructions (\eg, four
instructions) and their interleaving orders as an interleaving segment.


\begin{figure*}[t]
  \centering
  \includegraphics[width=0.9\linewidth]{fig/intuition.pdf}
  \caption{(a) A thread interleaving example of
    \autoref{fig:cve-2017-17712} that does not cause the concurrency
    bug, (b) interleaving pairs that access the same memory object,
    and (c) instruction segments composed of two instruction pairs.
    Note that we intentionally omit instructions that do not access
    globally-visible memory objects.}
  \label{fig:keyidea}
\end{figure*}
%
\autoref{fig:keyidea} visualizes our key idea.
%
Let us assume we execute the two system calls in
\autoref{fig:cve-2017-17712} concurrently.
%
\autoref{fig:keyidea-a} represents the thread interleaving of the
execution, where the uninitialized access bug does not manifest
because \texttt{B1} is executed after \texttt{A4} (\ie,
$(\texttt{A2} \Rightarrow \texttt{B1}) \wedge (\texttt{B1} \Rightarrow
\texttt{A4})$ is not satisfied).
%
In order to track interleaving orders of a small number (\eg, four) of
instructions, we decompose the thread interleaving into several
interleaving segments as described in \autoref{fig:keyidea-b}.
%
In these interleaving segments, \texttt{Segment \#1} contains three
memory access operations (\ie, \texttt{A2}, \texttt{A4}, and
\texttt{B1}), and describes interleaving orders such that \texttt{B1}
is executed after \texttt{A2} and \texttt{A4}.
%
Similarly, \texttt{Segment \#2} and \texttt{Segment \#3} describes
interleaving orders of four memory access operations, (\texttt{A2},
\texttt{B1}, \texttt{B2}, \texttt{A6}) and (\texttt{A4}, \texttt{B1},
\texttt{B2}, \texttt{A6}) respectively.
%

% With these interleaving segments, the fuzzer can be noticed that
% interleaving orders represented by these interelaving segments
% unlikley cause a concurrency bug.
% %
% Therefore, it is adequate for the fuzzer to search for unexplored
% interleaving segments (\eg, one that represents
% $(\texttt{A2} \Rightarrow \texttt{B1}) \wedge (\texttt{B1} \Rightarrow
% \texttt{A4})$) to maximize the chance of discovering concurrency bugs.


%
It is worth noting that interleaving segments can be overlapped; in
this example, \texttt{Segment \#1} and \texttt{Segment \#3} are
overlapped over an interleaving order
$\texttt{A4} \Rightarrow \texttt{B1}$.




\PP{Benefits of segmentizing thread interleaving}
%
Segmentizing thread interleaving provides two remarkable benefits to
the fuzzer as follows.



First, tracking interleaving segments is a befitting choice to
determine if any interesting thread interleaving remains untested.
%
As mentioned above, most concurrency bugs manifest depending only on
the execution order of four memory access operations. If the fuzzer
explores all interleaving segments with size of at most four, it is
unlikely that the fuzzer misses a concurrency bugs.
%
Accordingly, \textit{interleaving segments can be act as an
  interleaving coverage metric that allows a fuzzer to satisfy
  \textbf{R1}}.
  

In the example of \autoref{fig:cve-2017-17712}, \dr{TODO: conect to the exapmle}




Second, explored interleaving segments can be exploited to
\textit{direct} the fuzzer about what thread interleaving needs to be
explored in future.
%
\autoref{fig:hint} demonstrates how explored interleaving segments
can be helpful for future iterations.
%
As illustrated in \autoref{fig:hint}, the fuzzer can derive
\textit{unexplored} \texttt{Segment \#1*} by changing the execution
order of \texttt{A4} and \texttt{B4} in \textit{explored}
\texttt{Segment \#1}.
%
Since \texttt{Segment \#1*} satisfies
$(\texttt{A2} \Rightarrow \texttt{B1}) \wedge (\texttt{B1} \Rightarrow
\texttt{A4})$, the fuzzer can discover the uninitialized access bug if
it executes thread interleaving containing \texttt{Segment \#1*}.
%
In addition, the fuzzer can explore multiple interleaving segments at
a time.
%
Besides \texttt{Segment \#1*}, \texttt{Segment \#3*} can also be
derived from \texttt{Segment \#3}.
%
Interestingly, \texttt{Segment \#1*} and \texttt{Segment \#3*} can be
used to compose a new thread interleaving.
%
By executing a thread interleaving including the two derived
interleaving segments, the fuzzer is able to quickly test a number of
interleaving segments.
%
In this way, \textit{our proposed scheduler mechanism is designed to
  quickly explore unexplored interleaving segments, and to satisfy
  \textbf{R2}}.
%
\begin{figure}[t]
  \centering
  \includegraphics[width=0.9\linewidth]{fig/hint.pdf}
  \caption{\texttt{Segment \#1} and \texttt{Segment \#3} are explored
    interleaving segments in \autoref{fig:keyidea}.
    %
    From these two interleaving segments, our approach derives other
    interleaving segments \texttt{Segment \#1*} and \texttt{\#3*}, and
    schedules instructions to test the derived interleaving segments
    at the same time.}
  \label{fig:hint}
\end{figure}
%



\subsection{Interleaving Segment Coverage}
\label{ss:coverage}

\newcommand{\mutable}{mutable edge\xspace}
\newcommand{\mutables}{mutable edges\xspace}
\newcommand{\immutable}{immutable edge\xspace}
\newcommand{\immutables}{immutable edges\xspace}

Based on the key idea, we propose a novel concurrency coverage metric
called interleaving segment coverage.
%
Interleaving segment coverage is designed to track interleaving orders
of a small number of memory accesses, and if per-input interleaving
segment coverage is saturated, a fuzzer can confidently conclude that
the multi-thread input unlikely causes a concurrency bug.

\PP{Graph representation of interleaving segment}
%
We represent each interleaving segment as a small directed acyclic
graph (DAG) called an interleaving segment graph (shortly, segment
graph).
%
In this graph, vertices represent memory access operations, and edges
represent orderings between two memory access operations.
%
Specifically, there are two types of edges, program-order edges and
interleaving-order edges.
%
A program-order edge indicates the execution order between two memory
access operations in a single thread.
%
On the other hand, an interleaving-order edge indicates the execution
order between two memory access operations that 1) access the same
shared data, 2) at least one of them is a write operation, and 3) are
executed by different threads.

Taking the example of \texttt{Segment \#1},
\autoref{fig:interleavingsegmentgraph} illustrates a segment graph
corresponding to \texttt{Segment \#1}.
%
This segment graph contains a program-order edge from \texttt{A2} to
\texttt{A4} representing ``\texttt{A2} is executed before \texttt{A4}
in thread~A''.
%
In addition, the segment graph contains two more interleaving-order
edges. It contains an interleaving-order edge from \texttt{A2} to
\texttt{B1}, because 1) they access \texttt{inet->hdrincl}, 2)
\texttt{B1} is a write operations, and 3) they are executed by
different threads. Likewise, the segment graph also contains an
interleaving-order edge from \texttt{A4} to \texttt{B1}.

\begin{figure}[t]
  \centering
  \includegraphics[width=0.9\linewidth]{fig/interleavingsegmentgraph.pdf}
  \caption{\texttt{Segment \#1} and its segment graph. A
    dotted arrow represents a program order, and solid arrows
    represent interleaving orders.}
  \label{fig:interleavingsegmentgraph}
\end{figure}

It is worth noting that a segmentgraph has two properties. First, if
a path exists from a vertex \texttt{X} to another vertex \texttt{Y}, a
memory access operation corresponding to \texttt{X} is executed before
a memory access operation corresponding to \texttt{Y}.
%
\dr{}
This is because edges represent orderings that are a transitive
relation.
%
Second, \textit{all segment graph cannot contain a loop}.
%
If there is a loop exists, any vertex \texttt{Z} on the loop is
executed before itself, which is contradictory.


%
% Let us represent a memory access operation $M$ as four tuples,
% $(tid, addr, op, timestamp)$ where $tid$ is the identity of a thread,
% $addr$ is the address of a memory location, $op$ is the type of the
% memory access operation (\ie, $store$ or $load$), and $timestamp$
% indicates the point of time when the memory access operation is taken.
% %
% $M(x)$ detnoes a field $x$ of $M$. For example, $M(tid)$ is a $tid$
% field of a memory access operation $M$.
% %
% Also let us suppose all memory access operations are totally
% ordered. \ie, there are no two memory access operations that have the
% same $timestamp$.

% For all pair of memory access operations $M_i$ and $M_j$, we define a
% scheduling constraint $SC$ as a tuple $(M_i, M_j)$ if
% $M_i(tid) \neq M_j(tid)$, $M_i(addr) = M_j(addr)$,
% $M_i(op) = store \vee M_j(op) = store$, and
% $M_i(timestamp) < M_j(timestamp)$.
% %
% Informally, $M_i$ and $M_j$ are conflicting memory acceess operations
% that are executed in other threads, and $M_i$ was taken place before
% $M_j$.
% %
% For two scheduling constraint $SC_1(M_{1i}, M_{1j})$ and
% $SC_2(M_{2i}, M_{2j})$, $SC_1 = SC_2$ if
% $(M_{1i} = M_{2i}) \wedge (M_{1j} = M_{2j})$.
% %
% Then, we define a scheduling constraint pair $SCPair = (SC_i, SC_j)$
% for two scheduling constraints if $i < j$, $SC_i \neq SC_j$.
% %
% Lastly, biconflict coverage of the concurrent job $BC\mbox{-}Cov$ is
% defined as a set of all scheduling constraint pairs,
% $\{SCPair_1, SCPair_2, ..., SCPair_n\}$, constructed from its memory
% access operation sequence.


\PP{Tracking interleaving segment coverage}
%
Although interleaving segments can capture interesting characteristics
of an interleaving instance, it is not straightforward to use segment
graphs as an interleaving coverage metric because of two principal
impediments: 1) storing graphs (even though they are small) consumes a
lot of memory, and 2) it is not simple for the fuzzer to determine
whether a given segment graph is explored before or not.



To addresses the impediments, the fuzzer hashes each segment graph,
and interleaving segment coverage tracks a hash table of segment
graphs.
%
\dr{TODO: explain how to hash the graph}


% \dr{heuristic}
% %
% size 3 and 4
% %
% no containing a vertex that is not connected with interleaving order



We track interleaving segment coverage \textit{offline}; While
executing a multi-thread input, the fuzzer only collects memory access
operations annotated with timestamps, and after the execution is
finished, the fuzzer constructs an interleaving instance, and then
computes interleaving segment coverage of the multi-thread input.


\PP{Feedback from interleaving segment coverage}
%
New interleaving segment coverage provides two feedbacks to the
fuzzer.
%
First, the fuzzer notices that there are possibly more interesting
thread interleaivng remains untested. Therefore, the fuzzer spends
more computing power to explore more interesting thread interleaving.
%
Second, newly found segment graph directs how to explore the search
space of thread interleaving as detailed in \autoref{ss:scheduler}.





\subsection{Coverage-directed Thread Scheduling Control}
\label{ss:scheduler}
%
One important role of segment graphs are to infer unexplored
interleaving segments that the fuzzer will search for in future
iterations.
%
In this subsection, we explain how we generate scheduling points in
order to quickly saturate interleaivng segment coverage.

\PP{Deriving unexplored interleaving segement}
%
As described in \autoref{ss:overview}, explored interleaving segments
(\eg, \texttt{Segment \#1} in \autoref{fig:hint}) are used to infer
unexplored interleaving segments (\eg, \texttt{Segment \#1*}) that a
fuzzer will search for in future iterations.
%
In our approach, this is done by generating other segment graphs from
given segment graphs.

Let us denote $S_{new} = \{g_1, g_2, ..., g_n \}$ as a set of newly
explored segment graphs from a given interleaving instance, where
$g_i$ denotes a segment graph.
%
For each segment graph $g_i$, the fuzzer generates $S^{i}_{derived}$,
a set of derived segment graphs by permuting interleaving-order edges
in $g_i$.


\begin{figure}[t]
  \centering
  \includegraphics[width=0.9\linewidth]{fig/interleavingmutation.pdf}
  \caption{Example interleaving segment graphs derived from
    \texttt{Segment \#1}. The fuzzer will explore (a) and (b), but
    will not explore (c) contains a loop.}
  \label{fig:interleavingmutation}
\end{figure}
%

\autoref{fig:interleavingmutation} illustrates three examples of
derived segment graphs.
%
The fuzzer flips $\texttt{A4} \Rightarrow \texttt{B1}$ from a given
\texttt{Segment \#1} to generate another segment graph described in
(a).
%
The semantic behind ``\textit{flipping an interleaving edge}'' is
simple; it changes the interleaving order of an instruction pair that
access the shared data.
%
With the segmant graph of (a), the fuzzer will explore thread
interleaving that
$(\texttt{A2} \Rightarrow \texttt{B1}) \wedge (\texttt{B1} \Rightarrow
\texttt{A4})$ (\ie, the condition to cause the uninitialized access
bug).
%
Likewise, the fuzzer generates a segment graph of (b) by flipping both
of $\texttt{A2} \Rightarrow \texttt{B1}$ and
$\texttt{A4} \Rightarrow \texttt{B1}$.
%
Besides (a) and (b), flipping $\texttt{A2} \Rightarrow \texttt{B1}$
can generate the segment graph described in (c). However, This segment
graph is excluded because it contains a loop; a loop indicates a
contradiction on the execution order that any vertex on the loop
should be executed before itself.


It is worth noting that we do not flip program-order edges (\ie,
dotted arrows) with an assumption that thread interleaving do not
change the execution order of instructions executed by a single
thread.
%
In other words, our approach changes thread interleaving while
preserving the order in which instructions occur in the source code.



% Then, the fuzzer excludes 1) ones thas are explored before, and 2)
% ones that contain a loop.
% %
% The reason why the fuzzer excludes explored interleaving segment
% graphs is intuitive; the fuzzer wants to deprioritize interleaving
% segment graphs already explored (such as the case of (b)).
% %
% The fuzzer also excludes ones that contain a loop because.



As a last step, the fuzzer unions all sets of derived interleaving
segment graphs such that
$S_{derived} = S^{1}_{derived} \cup S^{2}_{derived} \cup ... \cup
S^{n}_{derived}$, and uses $S_{derived}$ later to generate scheduling
points.




\PP{Selecting interleaving segments to direct the fuzzer}
%
As described  \autoref{fig:hint}, multiple segment graphs can be
explored at a time (\ie, one thread interleaving comprises multiple
interleaving segments).
%
Thus, our strategy to to quickly consume $S_{derived}$ (\ie, a set of
derived and unexplored segment graphs) is selecting multiple
interleaving segments from $S_{derived}$, and explore them altogether.


However, not all interleaving segments cannot be explored together.
%
For example, in \autoref{fig:hint}, (a) and (b) cannot be explored
together; the segment graph (a) requires \texttt{A2} to be executed
before \texttt{B1} while the segment graph (b) requires the opposite
execution order between \texttt{A2} and \texttt{B1}.
%
Therefore, the fuzzer repeatedly selects and tests a subset of
$S_{derived}$ that is contradiction-free (\ie, does not make a
contradiction on the execution order) until $S_{derived}$ is empty.


It may require a heavy computation to identify the largest
contradiction-free subset of $S_{derived}$.
%
Instead of finding an optimal solution, we choose to adopt a greedy
heuristic.
%
Specifically, we start with an empty set $\bar{S}$. Then, we iterate
over derived segment graphs contained in given $S_{derived}$, and
determine adding each segment graph into $\bar{S}$ forms a loop or
not. If it does not form a loop, we add the segment graph into
$\bar{S}$.
%
After iterating all derived segment graphs in $S_{derived}$, $\bar{S}$
does not contain a loop. The fuzzer then excludes selected segment
graphs from the set of all derived segment graphs (\ie,
$S_{derived} = S_{derived} \setminus \bar{S}$), and generates
scheduling points to explore $\bar{S}$.









\PP{Generating scheduling points}
%
After selecting interleaving segment graphs, generating scheduling
points can be easily done by conducting a topological
sort~\cite{topologicalsort}.
%
Since an imaginary interleaving graph is acyclic, a topological sort
always returns a sequence of vertices (\ie, instructions) that does
not violate a program order.
%
It is well known that the time complexity of a topological sort is
$O(V+E)$. Considering that the graph is sparse, $E$ is a small value
so the time complexity can be asymptotically considered as $O(V)$.
%
In this sequence, scheduling points are just instructions that the
preemption should happen; \ie, the next instruction is executed by a
different thread.




%%% Local Variables:
%%% mode: latex
%%% TeX-master: "p"
%%% End:
